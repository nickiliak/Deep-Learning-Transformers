{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c5d3bd",
   "metadata": {},
   "source": [
    "# PIPELINE v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccdcd2",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f29cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import os\n",
    "from typing import List, Type\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Database Imports\n",
    "from sqlmodel import SQLModel, Field, Session, create_engine, select\n",
    "from sqlalchemy import Column, text\n",
    "from pgvector.sqlalchemy import Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf577a8",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7a52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file if present (this lets docker write a .env we can use locally)\n",
    "load_dotenv()\n",
    "\n",
    "# Database Connection (reads from environment; default points to local Docker DB)\n",
    "DATABASE_URL = os.environ.get(\n",
    "    \"DATABASE_URL\",\n",
    "    \"postgresql+psycopg://nick:secret@localhost:5433/vectordb\",\n",
    ")\n",
    "\n",
    "# Dataset Path (can be overridden via env)\n",
    "DATASET_PATH = os.environ.get(\n",
    "    \"DATASET_PATH\",\n",
    "    \"../data_filtered/corpus_filtered.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ac9c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick\\Desktop\\DTU Courses\\02456 Deep Learning\\Deep-Learning-Transformers\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Setup - Configure which model to use\n",
    "# Experiment A: BPE not ready yet\n",
    "# CURRENT_MODEL_ID = 'BPE'\n",
    "# CURRENT_TABLE_NAME = 'BPE'\n",
    "# VECTOR_DIMENSION = cuck\n",
    "# CURRENT_EMBEDDER = bpe\n",
    "\n",
    "# Experiment B: ByT5 (This one works)\n",
    "# CURRENT_MODEL_ID = 'google/byt5-small'\n",
    "# CURRENT_TABLE_NAME = 'byt5_small'\n",
    "# VECTOR_DIMENSION = 1472\n",
    "\n",
    "# Experiment C: Canine (This one should work have not tested yet delete this if you run it)\n",
    "CURRENT_MODEL_ID = 'google/canine-s'\n",
    "CURRENT_TABLE_NAME = 'canine_s'\n",
    "VECTOR_DIMENSION = 768\n",
    "\n",
    "# Experiment D: SentencePiece (Maybe coming soon who knows)\n",
    "# CURRENT_MODEL_ID = 'SentencePiece thing'\n",
    "# CURRENT_TABLE_NAME = 'sentencepiece'\n",
    "# VECTOR_DIMENSION = idk yet\n",
    "\n",
    "# Import embedders - simple relative import\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path (repo root from pipeline folder)\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "from tokenization.our_tokenizers.ByT5.ByT5_embedding import ByT5Embedder\n",
    "from tokenization.our_tokenizers.Canine.Canine_embedding import CanineEmbedder\n",
    "\n",
    "# Set embedder based on experiment\n",
    "CURRENT_EMBEDDER = CanineEmbedder  # Change this to CanineEmbedder for Experiment C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e271fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0.dev20241112+cu121\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "CUDA version: 12.1\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"⚠️  Running on CPU - embeddings will be slow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2adb7f",
   "metadata": {},
   "source": [
    "## Dynamic Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102d2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_class(table_name: str, dim: int) -> Type[SQLModel]:\n",
    "    \"\"\"\n",
    "    Dynamically creates a SQLModel class.\n",
    "    This allows us to save data to different tables (e.g., 'bert_v1', 'bert_v2')\n",
    "    without rewriting the class code manually.\n",
    "    \"\"\"\n",
    "    # We define the class attributes dynamically\n",
    "    class DynamicTable(SQLModel, table=True):\n",
    "        __tablename__ = table_name\n",
    "        __table_args__ = {'extend_existing': True} # Allows overwriting if class exists in memory\n",
    "\n",
    "        # Mapping CSV '_id' to primary key\n",
    "        id: str = Field(primary_key=True) \n",
    "        title: str\n",
    "        text: str\n",
    "        \n",
    "        # The Vector column\n",
    "        embedding: List[float] = Field(sa_column=Column(Vector(dim)))\n",
    "\n",
    "    return DynamicTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb985d",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e44e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(batch_embedding_size=32):\n",
    "    # A. Setup Database\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    \n",
    "    # Ensure pgvector extension exists\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))\n",
    "        conn.commit()\n",
    "\n",
    "    # B. Define the Table Model based on configuration\n",
    "    TableClass = create_table_class(CURRENT_TABLE_NAME, VECTOR_DIMENSION)\n",
    "    SQLModel.metadata.create_all(engine)\n",
    "\n",
    "    # C. Initialize ML Model\n",
    "    embedder = CURRENT_EMBEDDER(CURRENT_MODEL_ID)\n",
    "\n",
    "    # D. Process JSONL and Insert\n",
    "    if not os.path.exists(DATASET_PATH):\n",
    "        print(f\"Error: Dataset not found at {DATASET_PATH}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Processing JSONL: {DATASET_PATH} ---\")\n",
    "    print(f\"--- Target Table: {CURRENT_TABLE_NAME} ---\")\n",
    "    print(f\"--- Batch embedding size: {batch_embedding_size} (GPU batching enabled) ---\")\n",
    "\n",
    "    data_buffer = []\n",
    "    text_buffer = []\n",
    "    metadata_buffer = []\n",
    "    BATCH_SIZE = 100 \n",
    "\n",
    "    with Session(engine) as session:\n",
    "        # Open the JSONL file\n",
    "        with open(DATASET_PATH, mode='r', encoding='utf-8') as f:\n",
    "            \n",
    "            # Iterate line by line. \n",
    "            # We wrap 'f' with tqdm to show progress (lines processed)\n",
    "            for line in tqdm(f, desc=\"Embedding Docs\"):\n",
    "                try:\n",
    "                    if not line.strip():\n",
    "                        continue # Skip empty lines\n",
    "\n",
    "                    # 1. Parse JSON\n",
    "                    row = json.loads(line)\n",
    "\n",
    "                    # 2. Extract Data\n",
    "                    doc_id = row.get('_id')\n",
    "                    title = row.get('title', '')\n",
    "                    doc_text = row.get('text', '')\n",
    "\n",
    "                    # Skip if ID is missing\n",
    "                    if not doc_id:\n",
    "                        continue\n",
    "\n",
    "                    # 3. Prepare text and metadata for batch embedding\n",
    "                    full_content = f\"{title}: {doc_text}\"\n",
    "                    text_buffer.append(full_content)\n",
    "                    metadata_buffer.append({'id': doc_id, 'title': title, 'text': doc_text})\n",
    "\n",
    "                    # 4. Process batch when buffer is full\n",
    "                    if len(text_buffer) >= batch_embedding_size:\n",
    "                        # Generate embeddings in batch (GPU accelerated!)\n",
    "                        if hasattr(embedder, 'generate_embeddings_batch'):\n",
    "                            vectors = embedder.generate_embeddings_batch(text_buffer)\n",
    "                        else:\n",
    "                            # Fallback to single embedding if batch method not available\n",
    "                            vectors = [embedder.generate_embedding(text) for text in text_buffer]\n",
    "                        \n",
    "                        # Create records\n",
    "                        for meta, vector in zip(metadata_buffer, vectors):\n",
    "                            record = TableClass(\n",
    "                                id=meta['id'],\n",
    "                                title=meta['title'],\n",
    "                                text=meta['text'],\n",
    "                                embedding=vector\n",
    "                            )\n",
    "                            data_buffer.append(record)\n",
    "                        \n",
    "                        # Clear buffers\n",
    "                        text_buffer = []\n",
    "                        metadata_buffer = []\n",
    "\n",
    "                    # 5. Batch Commit to DB\n",
    "                    if len(data_buffer) >= BATCH_SIZE:\n",
    "                        session.add_all(data_buffer)\n",
    "                        session.commit()\n",
    "                        data_buffer = []\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping invalid JSON line\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing doc: {e}\")\n",
    "\n",
    "            # 6. Process remaining texts\n",
    "            if text_buffer:\n",
    "                if hasattr(embedder, 'generate_embeddings_batch'):\n",
    "                    vectors = embedder.generate_embeddings_batch(text_buffer)\n",
    "                else:\n",
    "                    vectors = [embedder.generate_embedding(text) for text in text_buffer]\n",
    "                    \n",
    "                for meta, vector in zip(metadata_buffer, vectors):\n",
    "                    record = TableClass(\n",
    "                        id=meta['id'],\n",
    "                        title=meta['title'],\n",
    "                        text=meta['text'],\n",
    "                        embedding=vector\n",
    "                    )\n",
    "                    data_buffer.append(record)\n",
    "\n",
    "            # 7. Commit remaining records\n",
    "            if data_buffer:\n",
    "                session.add_all(data_buffer)\n",
    "                session.commit()\n",
    "\n",
    "    print(\"\\n--- Pipeline Finished Successfully ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23555964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading CANINE Model: google/canine-s ---\n",
      "Using device: cuda\n",
      "--- Processing JSONL: ../data_filtered/corpus_filtered.jsonl ---\n",
      "--- Target Table: canine_s ---\n",
      "--- Batch embedding size: 8 (GPU batching enabled) ---\n",
      "--- Processing JSONL: ../data_filtered/corpus_filtered.jsonl ---\n",
      "--- Target Table: canine_s ---\n",
      "--- Batch embedding size: 8 (GPU batching enabled) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Docs: 79it [00:10,  7.23it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# if __name__ == \"__main__\":\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Run the full prgocess ADJUST EMBEDDING SIZE ACCORDING TO YOUR GPU IF OUT OF MEMORY USE SMALLER SIZE\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_embedding_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(batch_embedding_size)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text_buffer) >= batch_embedding_size:\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# Generate embeddings in batch (GPU accelerated!)\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(embedder, \u001b[33m'\u001b[39m\u001b[33mgenerate_embeddings_batch\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         vectors = \u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_embeddings_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     65\u001b[39m         \u001b[38;5;66;03m# Fallback to single embedding if batch method not available\u001b[39;00m\n\u001b[32m     66\u001b[39m         vectors = [embedder.generate_embedding(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m text_buffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nick\\Desktop\\DTU Courses\\02456 Deep Learning\\Deep-Learning-Transformers\\tokenization\\our_tokenizers\\Canine\\Canine_embedding.py:107\u001b[39m, in \u001b[36mCanineEmbedder.generate_embeddings_batch\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    104\u001b[39m sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=\u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Return as list of lists\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msentence_embeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.tolist()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# Run the full prgocess ADJUST EMBEDDING SIZE ACCORDING TO YOUR GPU IF OUT OF MEMORY USE SMALLER SIZE\n",
    "run_pipeline(batch_embedding_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
