{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c5d3bd",
   "metadata": {},
   "source": [
    "# PIPELINE v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccdcd2",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f29cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick\\Desktop\\DTU Courses\\02456 Deep Learning\\Deep-Learning-Transformers\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import embedders - simple relative import\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path (repo root from pipeline folder)\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "from tokenization.our_tokenizers.ByT5.ByT5_embedding import ByT5Embedder\n",
    "from tokenization.our_tokenizers.Canine.Canine_embedding import CanineEmbedder\n",
    "from tokenization.our_tokenizers.BPE.BPE_LSTM_embedding import BPELSTMEmbedder  # Uses trained LSTM\n",
    "from tokenization.our_tokenizers.BPE.BPE_transformer_embedding import BPETransformerEmbedder  # Uses trained Transformer\n",
    "#from tokenization.baseline.BERT.bert_embeddings import BertEmbedder\n",
    "\n",
    "# Set embedder based on experiment\n",
    "CURRENT_EMBEDDER = BPETransformerEmbedder  # Uses YOUR trained Transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf577a8",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7a52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file if present (this lets docker write a .env we can use locally)\n",
    "load_dotenv()\n",
    "\n",
    "# Database Connection (reads from environment; default points to local Docker DB)\n",
    "DATABASE_URL = os.environ.get(\n",
    "    \"DATABASE_URL\",\n",
    "    \"postgresql+psycopg://nick:secret@localhost:5433/vectordb\",\n",
    ")\n",
    "\n",
    "# Dataset Path (can be overridden via env)\n",
    "DATASET_PATH = os.environ.get(\n",
    "    \"DATASET_PATH\",\n",
    "    \"../data_filtered/corpus_filtered.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ac9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Configure which model to use\n",
    "# Experiment A: BPE with YOUR TRAINED LSTM\n",
    "# CURRENT_MODEL_ID = '../tokenization/vocabularies/bpe_tokenizer.json'\n",
    "# CURRENT_TABLE_NAME = 'bpe-lstm'\n",
    "# VECTOR_DIMENSION = 256  # LSTM hidden dim\n",
    "\n",
    "# Experiment B: BPE with YOUR TRAINED TRANSFORMER\n",
    "CURRENT_MODEL_ID = '../tokenization/vocabularies/bpe_tokenizer.json'\n",
    "CURRENT_TABLE_NAME = 'bpe-transformer'  # Match actual table in database\n",
    "VECTOR_DIMENSION = 256  # Transformer d_model\n",
    "\n",
    "# Experiment C: ByT5 (This one works)\n",
    "# CURRENT_MODEL_ID = 'google/byt5-small'\n",
    "# CURRENT_TABLE_NAME = 'byt5_small'\n",
    "# VECTOR_DIMENSION = 1472\n",
    "\n",
    "# Experiment D: Canine (This one should work have not tested yet delete this if you run it)\n",
    "# CURRENT_MODEL_ID = 'google/canine-s'\n",
    "# CURRENT_TABLE_NAME = 'canine_s'\n",
    "# VECTOR_DIMENSION = 768\n",
    "\n",
    "# Experiment E: Baseline BERT (Works)\n",
    "#CURRENT_MODEL_ID = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "#CURRENT_TABLE_NAME = 'bert_minilm'\n",
    "#VECTOR_DIMENSION = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e271fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0.dev20241112+cu121\n",
      "OS: Windows AMD64\n",
      "CUDA device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"OS: {platform.system()} {platform.machine()}\")\n",
    "\n",
    "# 1. check mops mac\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"ðŸš€ Running on MPS (Metal Performance Shaders) - M3 GPU Activated!\")\n",
    "    print(\"Accelerated performance enabled.\")\n",
    "    \n",
    "# 2. Ccuda check\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ Running on CPU - Embeddings will be slow\")\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2adb7f",
   "metadata": {},
   "source": [
    "## Dynamic Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102d2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, List\n",
    "from sqlmodel import SQLModel, Field, Session, create_engine, Column, text\n",
    "from pgvector.sqlalchemy import Vector\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_table_class(table_name: str, dim: int) -> Type[SQLModel]:\n",
    "    \"\"\"\n",
    "    Dynamically creates a SQLModel class.\n",
    "    This allows us to save data to different tables (e.g., 'bert_v1', 'bert_v2')\n",
    "    without rewriting the class code manually.\n",
    "    \"\"\"\n",
    "    # We define the class attributes dynamically\n",
    "    class DynamicTable(SQLModel, table=True):\n",
    "        __tablename__ = table_name\n",
    "        __table_args__ = {'extend_existing': True} # Allows overwriting if class exists in memory\n",
    "\n",
    "        # Mapping CSV '_id' to primary key\n",
    "        id: str = Field(primary_key=True) \n",
    "        title: str\n",
    "        text: str\n",
    "        \n",
    "        # The Vector column\n",
    "        embedding: List[float] = Field(sa_column=Column(Vector(dim)))\n",
    "\n",
    "    return DynamicTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb985d",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e44e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(batch_embedding_size=32, clear_existing=True):\n",
    "    # A. Setup Database\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    \n",
    "    # Ensure pgvector extension exists\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))\n",
    "        conn.commit()\n",
    "\n",
    "    # B. Clear existing table if requested\n",
    "    if clear_existing:\n",
    "        print(f\"--- Clearing existing table: {CURRENT_TABLE_NAME} ---\")\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(f'DROP TABLE IF EXISTS \"{CURRENT_TABLE_NAME}\"'))\n",
    "            conn.commit()\n",
    "\n",
    "    # C. Define the Table Model based on configuration\n",
    "    TableClass = create_table_class(CURRENT_TABLE_NAME, VECTOR_DIMENSION)\n",
    "    SQLModel.metadata.create_all(engine)\n",
    "\n",
    "    # D. Initialize ML Model\n",
    "    embedder = CURRENT_EMBEDDER(CURRENT_MODEL_ID)\n",
    "\n",
    "    # E. Process JSONL and Insert\n",
    "    if not os.path.exists(DATASET_PATH):\n",
    "        print(f\"Error: Dataset not found at {DATASET_PATH}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Processing JSONL: {DATASET_PATH} ---\")\n",
    "    print(f\"--- Target Table: {CURRENT_TABLE_NAME} ---\")\n",
    "    print(f\"--- Batch embedding size: {batch_embedding_size} (GPU batching enabled) ---\")\n",
    "\n",
    "    data_buffer = []\n",
    "    text_buffer = []\n",
    "    metadata_buffer = []\n",
    "    BATCH_SIZE = 100 \n",
    "\n",
    "    with Session(engine) as session:\n",
    "        # Open the JSONL file\n",
    "        with open(DATASET_PATH, mode='r', encoding='utf-8') as f:\n",
    "            \n",
    "            # Iterate line by line. \n",
    "            # We wrap 'f' with tqdm to show progress (lines processed)\n",
    "            for line in tqdm(f, desc=\"Embedding Docs\"):\n",
    "                try:\n",
    "                    if not line.strip():\n",
    "                        continue # Skip empty lines\n",
    "\n",
    "                    # 1. Parse JSON\n",
    "                    row = json.loads(line)\n",
    "\n",
    "                    # 2. Extract Data\n",
    "                    doc_id = row.get('_id')\n",
    "                    title = row.get('title', '')\n",
    "                    doc_text = row.get('text', '')\n",
    "\n",
    "                    # Skip if ID is missing\n",
    "                    if not doc_id:\n",
    "                        continue\n",
    "\n",
    "                    # 3. Prepare text and metadata for batch embedding\n",
    "                    full_content = f\"{title}: {doc_text}\"\n",
    "                    text_buffer.append(full_content)\n",
    "                    metadata_buffer.append({'id': doc_id, 'title': title, 'text': doc_text})\n",
    "\n",
    "                    # 4. Process batch when buffer is full\n",
    "                    if len(text_buffer) >= batch_embedding_size:\n",
    "                        # Generate embeddings in batch (GPU accelerated!)\n",
    "                        if hasattr(embedder, 'generate_embeddings_batch'):\n",
    "                            vectors = embedder.generate_embeddings_batch(text_buffer)\n",
    "                        else:\n",
    "                            # Fallback to single embedding if batch method not available\n",
    "                            vectors = [embedder.generate_embedding(text) for text in text_buffer]\n",
    "                        \n",
    "                        # Create records\n",
    "                        for meta, vector in zip(metadata_buffer, vectors):\n",
    "                            record = TableClass(\n",
    "                                id=meta['id'],\n",
    "                                title=meta['title'],\n",
    "                                text=meta['text'],\n",
    "                                embedding=vector\n",
    "                            )\n",
    "                            data_buffer.append(record)\n",
    "                        \n",
    "                        # Clear buffers\n",
    "                        text_buffer = []\n",
    "                        metadata_buffer = []\n",
    "\n",
    "                    # 5. Batch Commit to DB\n",
    "                    if len(data_buffer) >= BATCH_SIZE:\n",
    "                        session.add_all(data_buffer)\n",
    "                        session.commit()\n",
    "                        data_buffer = []\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping invalid JSON line\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing doc: {e}\")\n",
    "\n",
    "            # 6. Process remaining texts\n",
    "            if text_buffer:\n",
    "                if hasattr(embedder, 'generate_embeddings_batch'):\n",
    "                    vectors = embedder.generate_embeddings_batch(text_buffer)\n",
    "                else:\n",
    "                    vectors = [embedder.generate_embedding(text) for text in text_buffer]\n",
    "                    \n",
    "                for meta, vector in zip(metadata_buffer, vectors):\n",
    "                    record = TableClass(\n",
    "                        id=meta['id'],\n",
    "                        title=meta['title'],\n",
    "                        text=meta['text'],\n",
    "                        embedding=vector\n",
    "                    )\n",
    "                    data_buffer.append(record)\n",
    "\n",
    "            # 7. Commit remaining records\n",
    "            if data_buffer:\n",
    "                session.add_all(data_buffer)\n",
    "                session.commit()\n",
    "\n",
    "    print(\"\\n--- Pipeline Finished Successfully ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23555964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Clearing existing table: bpe-transformer ---\n",
      "--- Loading BPE Embedder (TRAINED TRANSFORMER) ---\n",
      "Device: cuda\n",
      "Tokenizer loaded from ../tokenization/vocabularies/bpe_tokenizer.json\n",
      "Loading trained Transformer from: c:\\Users\\nick\\Desktop\\DTU Courses\\02456 Deep Learning\\Deep-Learning-Transformers\\models\\Transformer\\transformer_bpe_best.pt\n",
      "âœ… Loaded trained Transformer (embedding dimension: 256)\n",
      "--- Processing JSONL: ../data_filtered/corpus_filtered.jsonl ---\n",
      "--- Target Table: bpe-transformer ---\n",
      "--- Batch embedding size: 16 (GPU batching enabled) ---\n",
      "âœ… Loaded trained Transformer (embedding dimension: 256)\n",
      "--- Processing JSONL: ../data_filtered/corpus_filtered.jsonl ---\n",
      "--- Target Table: bpe-transformer ---\n",
      "--- Batch embedding size: 16 (GPU batching enabled) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Docs: 589it [00:22, 25.96it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pipeline Finished Successfully ---\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# Run the full prgocess ADJUST EMBEDDING SIZE ACCORDING TO YOUR GPU IF OUT OF MEMORY USE SMALLER SIZE\n",
    "run_pipeline(batch_embedding_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
