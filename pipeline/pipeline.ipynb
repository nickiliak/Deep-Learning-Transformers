{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c5d3bd",
   "metadata": {},
   "source": [
    "# PIPELINE v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccdcd2",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20f29cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import os\n",
    "from typing import List, Type\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Database Imports\n",
    "from sqlmodel import SQLModel, Field, Session, create_engine, select\n",
    "from sqlalchemy import Column, text\n",
    "from pgvector.sqlalchemy import Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf577a8",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f7a52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file if present (this lets docker write a .env we can use locally)\n",
    "load_dotenv()\n",
    "\n",
    "# Database Connection (reads from environment; default points to local Docker DB)\n",
    "DATABASE_URL = os.environ.get(\n",
    "    \"DATABASE_URL\",\n",
    "    \"postgresql+psycopg://nick:secret@localhost:5433/vectordb\",\n",
    ")\n",
    "\n",
    "# Dataset Path (can be overridden via env)\n",
    "DATASET_PATH = os.environ.get(\n",
    "    \"DATASET_PATH\",\n",
    "    \"../data_filtered/corpus_filtered.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Configure which model to use\n",
    "# Experiment A: BPE not ready yet\n",
    "#CURRENT_MODEL_ID = '..\\\\tokenization\\\\vocabularies\\\\bpe_tokenizer.json'\n",
    "#CURRENT_TABLE_NAME = 'BPE'\n",
    "#VECTOR_DIMENSION = 768\n",
    "#\n",
    "\n",
    "# Experiment B: ByT5 (This one works)\n",
    "# CURRENT_MODEL_ID = 'google/byt5-small'\n",
    "# CURRENT_TABLE_NAME = 'byt5_small'\n",
    "# VECTOR_DIMENSION = 1472\n",
    "\n",
    "# Experiment C: Canine (This one should work have not tested yet delete this if you run it)\n",
    "CURRENT_MODEL_ID = 'google/canine-s'\n",
    "CURRENT_TABLE_NAME = 'canine_s'\n",
    "VECTOR_DIMENSION = 768\n",
    "\n",
    "# Experiment D: SentencePiece (Maybe coming soon who knows)\n",
    "# CURRENT_MODEL_ID = 'SentencePiece thing'\n",
    "# CURRENT_TABLE_NAME = 'sentencepiece'\n",
    "# VECTOR_DIMENSION = idk yet\n",
    "\n",
    "# Import embedders - simple relative import\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path (repo root from pipeline folder)\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "from tokenization.our_tokenizers.ByT5.ByT5_embedding import ByT5Embedder\n",
    "from tokenization.our_tokenizers.Canine.Canine_embedding import CanineEmbedder\n",
    "from tokenization.our_tokenizers.BPE.BPE_embedding import BPEEmbedder\n",
    "# Set embedder based on experiment\n",
    "CURRENT_EMBEDDER = CanineEmbedder  # Change this to CanineEmbedder for Experiment C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6e271fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0.dev20251203\n",
      "OS: Darwin arm64\n",
      "ðŸš€ Running on MPS (Metal Performance Shaders) - M3 GPU Activated!\n",
      "Accelerated performance enabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"OS: {platform.system()} {platform.machine()}\")\n",
    "\n",
    "# 1. check mops mac\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"ðŸš€ Running on MPS (Metal Performance Shaders) - M3 GPU Activated!\")\n",
    "    print(\"Accelerated performance enabled.\")\n",
    "    \n",
    "# 2. Ccuda check\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ Running on CPU - Embeddings will be slow\")\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2adb7f",
   "metadata": {},
   "source": [
    "## Dynamic Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "102d2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_class(table_name: str, dim: int) -> Type[SQLModel]:\n",
    "    \"\"\"\n",
    "    Dynamically creates a SQLModel class.\n",
    "    This allows us to save data to different tables (e.g., 'bert_v1', 'bert_v2')\n",
    "    without rewriting the class code manually.\n",
    "    \"\"\"\n",
    "    # We define the class attributes dynamically\n",
    "    class DynamicTable(SQLModel, table=True):\n",
    "        __tablename__ = table_name\n",
    "        __table_args__ = {'extend_existing': True} # Allows overwriting if class exists in memory\n",
    "\n",
    "        # Mapping CSV '_id' to primary key\n",
    "        id: str = Field(primary_key=True) \n",
    "        title: str\n",
    "        text: str\n",
    "        \n",
    "        # The Vector column\n",
    "        embedding: List[float] = Field(sa_column=Column(Vector(dim)))\n",
    "\n",
    "    return DynamicTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb985d",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e44e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(batch_embedding_size=32):\n",
    "    # A. Setup Database\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    \n",
    "    # Ensure pgvector extension exists\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))\n",
    "        conn.commit()\n",
    "\n",
    "    # B. Define the Table Model based on configuration\n",
    "    TableClass = create_table_class(CURRENT_TABLE_NAME, VECTOR_DIMENSION)\n",
    "    SQLModel.metadata.create_all(engine)\n",
    "\n",
    "    # C. Initialize ML Model\n",
    "    embedder = CURRENT_EMBEDDER(CURRENT_MODEL_ID)\n",
    "\n",
    "    # D. Process JSONL and Insert\n",
    "    if not os.path.exists(DATASET_PATH):\n",
    "        print(f\"Error: Dataset not found at {DATASET_PATH}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Processing JSONL: {DATASET_PATH} ---\")\n",
    "    print(f\"--- Target Table: {CURRENT_TABLE_NAME} ---\")\n",
    "    print(f\"--- Batch embedding size: {batch_embedding_size} (GPU batching enabled) ---\")\n",
    "\n",
    "    data_buffer = []\n",
    "    text_buffer = []\n",
    "    metadata_buffer = []\n",
    "    BATCH_SIZE = 100 \n",
    "\n",
    "    with Session(engine) as session:\n",
    "        # Open the JSONL file\n",
    "        with open(DATASET_PATH, mode='r', encoding='utf-8') as f:\n",
    "            \n",
    "            # Iterate line by line. \n",
    "            # We wrap 'f' with tqdm to show progress (lines processed)\n",
    "            for line in tqdm(f, desc=\"Embedding Docs\"):\n",
    "                try:\n",
    "                    if not line.strip():\n",
    "                        continue # Skip empty lines\n",
    "\n",
    "                    # 1. Parse JSON\n",
    "                    row = json.loads(line)\n",
    "\n",
    "                    # 2. Extract Data\n",
    "                    doc_id = row.get('_id')\n",
    "                    title = row.get('title', '')\n",
    "                    doc_text = row.get('text', '')\n",
    "\n",
    "                    # Skip if ID is missing\n",
    "                    if not doc_id:\n",
    "                        continue\n",
    "\n",
    "                    # 3. Prepare text and metadata for batch embedding\n",
    "                    full_content = f\"{title}: {doc_text}\"\n",
    "                    text_buffer.append(full_content)\n",
    "                    metadata_buffer.append({'id': doc_id, 'title': title, 'text': doc_text})\n",
    "\n",
    "                    # 4. Process batch when buffer is full\n",
    "                    if len(text_buffer) >= batch_embedding_size:\n",
    "                        # Generate embeddings in batch (GPU accelerated!)\n",
    "                        if hasattr(embedder, 'generate_embeddings_batch'):\n",
    "                            vectors = embedder.generate_embeddings_batch(text_buffer)\n",
    "                        else:\n",
    "                            # Fallback to single embedding if batch method not available\n",
    "                            vectors = [embedder.generate_embedding(text) for text in text_buffer]\n",
    "                        \n",
    "                        # Create records\n",
    "                        for meta, vector in zip(metadata_buffer, vectors):\n",
    "                            record = TableClass(\n",
    "                                id=meta['id'],\n",
    "                                title=meta['title'],\n",
    "                                text=meta['text'],\n",
    "                                embedding=vector\n",
    "                            )\n",
    "                            data_buffer.append(record)\n",
    "                        \n",
    "                        # Clear buffers\n",
    "                        text_buffer = []\n",
    "                        metadata_buffer = []\n",
    "\n",
    "                    # 5. Batch Commit to DB\n",
    "                    if len(data_buffer) >= BATCH_SIZE:\n",
    "                        session.add_all(data_buffer)\n",
    "                        session.commit()\n",
    "                        data_buffer = []\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping invalid JSON line\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing doc: {e}\")\n",
    "\n",
    "            # 6. Process remaining texts\n",
    "            if text_buffer:\n",
    "                if hasattr(embedder, 'generate_embeddings_batch'):\n",
    "                    vectors = embedder.generate_embeddings_batch(text_buffer)\n",
    "                else:\n",
    "                    vectors = [embedder.generate_embedding(text) for text in text_buffer]\n",
    "                    \n",
    "                for meta, vector in zip(metadata_buffer, vectors):\n",
    "                    record = TableClass(\n",
    "                        id=meta['id'],\n",
    "                        title=meta['title'],\n",
    "                        text=meta['text'],\n",
    "                        embedding=vector\n",
    "                    )\n",
    "                    data_buffer.append(record)\n",
    "\n",
    "            # 7. Commit remaining records\n",
    "            if data_buffer:\n",
    "                session.add_all(data_buffer)\n",
    "                session.commit()\n",
    "\n",
    "    print(\"\\n--- Pipeline Finished Successfully ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23555964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading BPE tokenizer and building embedder ---\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bulacio/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/0. DTU/02456-deeplearning/project/Deep-Learning-Transformers/.venv/lib/python3.12/site-packages/sqlmodel/main.py:644: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.DynamicTable, and will be replaced in the string-lookup table.\n",
      "  DeclarativeMeta.__init__(cls, classname, bases, dict_, **kw)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'google/canine-s'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# if __name__ == \"__main__\":\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Run the full prgocess ADJUST EMBEDDING SIZE ACCORDING TO YOUR GPU IF OUT OF MEMORY USE SMALLER SIZE\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_embedding_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(batch_embedding_size)\u001b[39m\n\u001b[32m     12\u001b[39m SQLModel.metadata.create_all(engine)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# C. Initialize ML Model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m embedder = \u001b[43mCURRENT_EMBEDDER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCURRENT_MODEL_ID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# D. Process JSONL and Insert\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(DATASET_PATH):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/0. DTU/02456-deeplearning/project/Deep-Learning-Transformers/tokenization/our_tokenizers/BPE/BPE_embedding.py:42\u001b[39m, in \u001b[36mBPEEmbedder.__init__\u001b[39m\u001b[34m(self, bpe_model_path, d_model, max_length)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Load trained BPE tokenizer\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mself\u001b[39m.tokenizer = CustomBPETokenizer()\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbpe_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Build vocabulary & embedding\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     47\u001b[39m vocab = \u001b[38;5;28mself\u001b[39m.tokenizer.build_vocab()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/0. DTU/02456-deeplearning/project/Deep-Learning-Transformers/tokenization/our_tokenizers/BPE/BPE_tokenization.py:139\u001b[39m, in \u001b[36mCustomBPETokenizer.load\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    140\u001b[39m         obj = json.load(f)\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mself\u001b[39m.vocab_size = obj[\u001b[33m\"\u001b[39m\u001b[33mvocab_size\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'google/canine-s'"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# Run the full prgocess ADJUST EMBEDDING SIZE ACCORDING TO YOUR GPU IF OUT OF MEMORY USE SMALLER SIZE\n",
    "run_pipeline(batch_embedding_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c91e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
